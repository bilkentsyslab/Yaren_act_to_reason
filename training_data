"""
Simulation script to observe a dynamic agent replacing a vehicle which is selected
and recorded in vs_always6_final_filtered or vs_startsAt7_endsAt6_final_filtered
Two types of situations are simulated: no_followers and with_followers
These indicate that vehicles that stay behind the ego on the same lane are ignored
in order to prevent these crashing into the ego from the rear
"""
from Params import Params
from DynamicDQNAgent import DynamicDQNAgent
from Training import Training
import pandas as pd 
import numpy as np
import os 
from State import State
from pathlib import Path


EGO_DF_DYN_COLS = ['Episode', 'Time_Step', 'State', 'fs_d', 'fs_v', 'fc_d', 
                   'fc_v', 'rs_d', 'rs_v', 'velocity', 'lane', 'dist_end_merging', 
                   'q-lev1', 'q-lev2', 'q-lev3', 'q-maintain1', 'q-accel1', 
                   'q-decel1', 'q-hard_accel1', 'q-hard_decel1', 'q-merge1',
                   'q-maintain2', 'q-accel2', 'q-decel2', 'q-hard_accel2', 
                   'q-hard_decel2', 'q-merge2', 'q-maintain3', 'q-accel3', 
                   'q-decel3', 'q-hard_accel3', 'q-hard_decel3', 'q-merge3', 
                   'Dynamic_Action', 'Dynamic_Action_Type', 'Action']


EXPERIMENT_TITLE = "some_title/"
EXPERIMENT_PATH = os.path.split(os.getcwd())[0]+"/Act-to-reason-original/experiments/" # Path of the experiment where level-k training files are located
DATA_PATH = os.path.split(os.getcwd())[0]+"data/"
RESULTS_PATH = DATA_PATH+"NGSIM_I80_sim_results/"
Path("./"+RESULTS_PATH).mkdir(parents=True, exist_ok=True)
EXP_RES_DIR = ""

EGO_IDs = pd.read_csv(DATA_PATH+"vs_always6_final_filtered.csv")
EGO_IDs = pd.concat([EGO_IDs, pd.read_csv(DATA_PATH+"vs_startsAt7_endsAt6_final_filtered.csv")], axis=0)

SAMPLING_FREQ = 10 # Sampling frequency of the dataset
# Frames to skip in the dataset (Dataset is sampled in 10Hz)
# So every $SKIP_FRAMES$, the ego's observation will be reset from the dataset
SKIP_FRAMES = int(Params.timestep * 10) #time correspondance = 0.5*10 = 5sec 
# Section duration in seconds, if simulation is to be run in sections rather than episodes
SECTION_DUR = 10 #skip frames at each 5 secs, waitr 10secs for section (?)

MODEL_LEVEL1 = 99 # Model number of the level1 DQN
MODEL_LEVEL2 = 99 # Model number of the level2 DQN
MODEL_LEVEL3 = 99 # Model number of the level3 DQN
MODEL_DYNAMIC = 110  # Model number of the dynamic DQN

# Boltzmann sampling for dynamic policy to select a reasoning action
ENABLE_BOLTZMANN_SAMPLING = True 
# Boltzmann sampling for level-k policy to select a driving action
ENABLE_DYNAMIC_DRIVING_BOLTZMANN_SAMPLING = True #TODO 
# Random reasoning action selection for the dynamic agent
ENABLE_RANDOM_DYNAMIC_STRATEGY = False

STATE_SIZE = Params.num_observations
ACTION_SIZE = Params.num_actions
DYNAMIC_STATE_SIZE = Params.num_observations * Params.dynamic_history + \
    Params.dynamic_history_action * (Params.dynamic_history-1)
DYNAMIC_ACTION_SIZE = Params.num_dynamic_actions  

DYNAMIC_AGENT = None
EPISODE_DF = None
SECTION_DF = None
EGO_ID = None

FINAL_STATE_DF_COLUMNS = ['Run_No','Final_State','Real_Final_Step','Sim_Final_Step']

#Normalize state variables
def normalize_state(state):
    msg = []
    msg.append(state[0]/Params.max_sight_distance) #fs_d
    msg.append(state[1]/(Params.max_speed-Params.min_speed)) #fs_v
    msg.append(state[2]/Params.max_sight_distance) #fc_d
    msg.append(state[3]/(Params.max_speed-Params.min_speed)) #fc_v
    msg.append(state[4]/Params.max_sight_distance) #rs_d
    msg.append(state[5]/(Params.max_speed-Params.min_speed)) #rs_v
    msg.append(state[6]/(Params.max_speed-Params.min_speed)) #vel
    msg.append(state[7]) #lane
    if state[8]>Params.merging_region_length: #dist_end_merging
        msg.append(1)
    elif state[8]<-Params.merging_region_length: #dist_end_merging
        msg.append(-1)
    else:    
        msg.append(state[8]/Params.merging_region_length) #dist_end_merging
    return msg

#Finds and returns the state of the car given
#Definition of variable names can be found in Message.py
def get_Message(frame_id,ego_current_df,normalize=True):
    frame_df = EPISODE_DF.loc[EPISODE_DF['Frame_ID']==frame_id]
    
    ego_vel = ego_current_df['Mean_Speed'].item()
    ego_pos = ego_current_df['Local_Y'].item()
    ego_lane = ego_current_df['Lane_ID'].item()
    ego_len = ego_current_df['Vehicle_Length'].item()
    
    fs_d = Params.max_sight_distance
    fs_v = Params.max_speed - ego_vel + 0.1
    fc_d = Params.max_sight_distance
    fc_v = Params.max_speed - ego_vel + 0.1        
    rs_d = -Params.max_sight_distance
    rs_v = Params.min_speed - ego_vel - 0.1       

    car_fc = False
    car_fr = False
    for v_id in frame_df.Vehicle_ID:
        if v_id == EGO_ID:
            continue

        v_df = frame_df.loc[frame_df['Vehicle_ID']==v_id]
        v_vel = v_df['Mean_Speed'].item()
        v_pos = v_df['Local_Y'].item()
        v_lane = v_df['Lane_ID'].item()      
        v_len = v_df['Vehicle_Length'].item()
                
        if v_pos > Params.end_merging_point + v_len and v_lane == 0:
            continue
        
        rel_position = v_pos - ego_pos
        rel_velocity = v_vel - ego_vel

        if v_lane == (ego_lane + 1):
            if -ego_len > rel_position > rs_d:
                rs_d = rel_position + ego_len
                rs_v = rel_velocity
            elif 0 > rel_position > rs_d:
                rs_d = 0
                rs_v = rel_velocity
            elif v_len <= rel_position < fs_d:
                fs_d = rel_position - v_len
                fs_v = rel_velocity
            elif 0 <= rel_position < fs_d:
                fs_d = 0
                fs_v = rel_velocity
        elif v_lane == (ego_lane - 1):
            if -ego_len > rel_position > rs_d:
                rs_d = rel_position + ego_len
                rs_v = rel_velocity
            elif 0 > rel_position > rs_d:
                rs_d = 0
                rs_v = rel_velocity
            elif v_len <= rel_position < fs_d:
                car_fr = True
                fs_d = rel_position - v_len
                fs_v = rel_velocity
            elif 0 <= rel_position < fs_d:
                car_fr = True
                fs_d = 0
                fs_v = rel_velocity
        elif v_lane == ego_lane:
            if v_len <= rel_position < fc_d:
                car_fc = True
                fc_d = rel_position - v_len
                fc_v = rel_velocity
            elif 0 <= rel_position < fc_d:
                car_fc = True
                fc_d = 0
                fc_v = rel_velocity
            
    if (ego_lane == 0) and ((Params.end_merging_point - Params.max_sight_distance) <= ego_pos <= Params.end_merging_point) and not car_fc: 
        fc_d = Params.end_merging_point - ego_pos
        fc_v = -ego_vel
    elif (ego_lane == 1) and ((Params.end_merging_point - Params.max_sight_distance) <= ego_pos <= Params.end_merging_point) and not car_fr: 
        fs_d = Params.end_merging_point - ego_pos
        fs_v = -ego_vel

    if ego_lane == 1 and ego_pos >= Params.end_merging_point:
        fs_d = 0
        fs_v = 0

    msg = [fs_d, fs_v, fc_d, fc_v,
           rs_d, rs_v, ego_vel, ego_lane,
           Params.end_merging_point - ego_pos]
    if normalize:
        msg = normalize_state(msg)
    return msg

#Check collision status of ego
def collision_check(frame_id,ego_df):
    ego_len = ego_df['Vehicle_Length'].iloc[-1]

    for temp_frame_id in range(frame_id+1,frame_id+SKIP_FRAMES+1):
        ego_pos = ego_df.loc[ego_df['Frame_ID']==temp_frame_id].Local_Y.item()
        ego_lane = ego_df.loc[ego_df['Frame_ID']==temp_frame_id].Lane_ID.item()        
        
        frame_df = EPISODE_DF.loc[EPISODE_DF['Frame_ID']==temp_frame_id]
        for v_id in frame_df.Vehicle_ID:   #all the vehicles in that 
            if v_id == EGO_ID:
                if ego_lane == 0 and (ego_pos >= Params.end_merging_point):
                    return [True,0]  #no collision, already passed??
                continue    
            
            v_df = EPISODE_DF.loc[EPISODE_DF['Vehicle_ID']==v_id]
            v_len = v_df.loc[v_df['Frame_ID']==temp_frame_id].Vehicle_Length.item()
            v_pos = v_df.loc[v_df['Frame_ID']==temp_frame_id].Local_Y.item()
            v_lane = v_df.loc[v_df['Frame_ID']==temp_frame_id].Lane_ID.item()

            # CURRENT AND PREVIOUS ACTIONS ?
            if (-ego_len <= v_pos-ego_pos <= (v_len + 0.1) and ego_lane == v_lane):
                for temp_past_frame_id in range(frame_id+1,temp_frame_id):
                    if (v_df['Frame_ID']==temp_past_frame_id).any():
                        v_lane_past = v_df.loc[v_df['Frame_ID']==temp_past_frame_id].Lane_ID.item()
                        if (v_lane_past != v_lane):
                            return [True,1] # A car merged into ego
                    ego_lane_past = ego_df.loc[ego_df['Frame_ID']==temp_past_frame_id].Lane_ID.item()
                    if (ego_lane != ego_lane_past):
                        return [True,2] #  Ego merged into a car 
                if v_pos > ego_pos:
                    return [True,3]
                elif ego_pos > v_pos:
                    return [True,5]
                else:
                    print("Unindentified Collision at step "+str(temp_frame_id))
        return [False,-1]                       
            

def translate_car0_state(ego_state):
    return Params.car0_states[ego_state]


def remember_frame(currentstate, actionget, nextstate, reward, done, 
                       ego_reached_end, state_size, dynamic_actionget = None):
        """
        Appends a given transition to the memory

        Parameters
        ----------
        currentstate : numpy array
            Current state of the ego.
        actionget : int
            Current driving action of the ego.
        dynamic_actionget : int
            Current level-k action of the dynamic ego.
        nextstate : numpy array
            Next state of the ego.
        reward : float
            Reward taken with the current action.
        done : bool
            True if ego is in a collision.
        ego_reached_end : bool
            True if ego reached the end.
        state_size : int
            Size of the state, i.e. the input layer.

        Returns
        -------
        None.

        """
        # Dynamic ego
        temp_nextstate = nextstate.copy()
        nextstate = currentstate.copy()
        if Params.dynamic_history_action:
            scale_action = 1.0 if not Params.scale_action else (Params.num_actions-1.0)
            nextstate_concat = np.concatenate((nextstate[0,0,:Params.num_actions].copy(),
                                                [actionget/scale_action],
                                                nextstate[0,0,Params.num_actions:-state_size].copy()))
            nextstate[0,0,Params.num_actions:] = nextstate_concat
        else:
            nextstate[0,0,Params.num_actions:] = nextstate[0,0,:-Params.num_actions].copy()
        nextstate[:,:, :Params.num_actions] = temp_nextstate.copy()
        DYNAMIC_AGENT.remember(currentstate, 
                                        dynamic_actionget, 
                                        reward, nextstate, 
                                        (done or ego_reached_end))
    
def get_reward(crash, nextstate, ego_velocity, ego_lane, fc_d, dist_end_merging, x_sim, x_data, lane_sim, lane_data):
    performance = 1.0
    scale = 1.0 # 0.02
    
    wc = 1000 * scale # 1000 #   Collision
    wv = 5 * scale * performance # Velocity
    we = 5 * scale #*performance # Effort
    wh = 5 * scale # Headway
    wnm = 5 * scale #*performance # Not Merging
    ws = 100 * scale # 100  #  *performance # Velocity Less than 2.25m/s or Stopping on Lane-0 with dist_end_merging less than far distance
    w7 = 1 #TODO tune
    w8 = 1 #TODO tune

    c = 0
    if crash:
        c = -1
        
    # Velocity
    v_coeff = 1 # 0.2
    if ego_velocity > Params.nominal_speed:
        v = v_coeff*(ego_velocity - Params.nominal_speed)/(Params.max_speed - Params.nominal_speed)
    else:
        v = (ego_velocity - Params.nominal_speed)/(Params.nominal_speed-Params.min_speed)
    
    # Effort #TODO  nextstate[3]=effort=?cars_info2[3,0]
    if ego_velocity > (Params.nominal_speed+Params.min_speed)/2:
        if nextstate[3] == 0:
            e = 0
        elif nextstate[3] == 1:
            e = -0.25
        elif nextstate[3] == 2:
            e = -1
        else:
            e = 0
    else:
        e = 0
    
    # Headway
    h = 0
    fc_d = nextstate[2]*Params.max_sight_distance
    if fc_d <= Params.close_distance:
        h = -1
    elif fc_d <= Params.nominal_distance:
        h = 1*(fc_d-Params.nominal_distance)/(Params.nominal_distance-Params.close_distance)
    elif ego_velocity > -Params.hard_decel_rate*Params.timestep: #TODO timestep uyuşuyor mu
        if fc_d <= Params.far_distance:
            h = 1*(fc_d - Params.nominal_distance)/(Params.far_distance-Params.nominal_distance)
        elif fc_d > Params.far_distance:
            h = 1
    
    # Not Merging
    nm = 0
    if ego_lane == 0:  # Staying on Lane-0 
        nm = -1 

    # Stopping
    s = 0
    if ego_velocity <= -Params.hard_decel_rate*Params.timestep:
        dist_end_merging = nextstate[-1]*Params.merging_region_length 
        if fc_d >= Params.far_distance:
            s = -1
        elif ego_lane == 0 and 0 <= dist_end_merging <= Params.far_distance:
            # s = -0.05
            fl_d = nextstate[0]*Params.max_sight_distance
            rl_d = nextstate[4]*Params.max_sight_distance
            if fl_d >= Params.close_distance and rl_d <= -1.5*Params.far_distance:
            # if fl_d >= Params.nominal_distance and rl_d <= -1.5*Params.far_distance:
                s = -1
            else:
                s = -0.05
            
    # Calibration term for x-axis offset (ox)
    x_diff = abs(x_sim - x_data)
    if x_diff > 30:
        ox = 0
    else:
        ox = 1 - (x_diff / 30)

    # Calibration term for y-axis (lane offset oy)
    oy = 1 if lane_sim != lane_data else 0

    # Final reward with calibration terms
    R = wc * c + wv * v + we * e + wh * h + wnm * nm + ws * s
    R_calib = R + ox * w7 + oy * w8

    return R_calib
     


def update_motion(ego_df, frame_id,act):
    
    ego_class_id = ego_df['Vehicle_Class_ID'].iloc[-1]
    ego_len = ego_df['Vehicle_Length'].iloc[-1]
    ego_follower_id = ego_df['Follower_ID'].iloc[-1]
    ego_leader_id = ego_df['Leader_ID'].iloc[-1]
    ego_pos = ego_df['Local_Y'].iloc[-1]    
    ego_lane = ego_df['Lane_ID'].iloc[-1]
    ego_vel = ego_df['Mean_Speed'].iloc[-1]
        
    acc = 0 
    epsilon = 0.1
    timestep = Params.timestep/SKIP_FRAMES
    
    new_lane = ego_lane
    new_vel = ego_vel
    new_pos = ego_pos
    
    # Merge
    if act == 5:
        new_lane += 1
    #Implements accelerate action by sampling an acceleration
    elif act == 1 and ego_vel < (Params.max_speed - epsilon):
        acc = min(0.25 + np.random.exponential(scale=0.75), Params.actions[act][1])

    #Implements decelerate action by sampling an acceleration
    elif act == 2 and ego_vel> (Params.min_speed + epsilon):
        acc = max(-0.25 - np.random.exponential(scale=0.75),Params.actions[act][1])

    #Implements hard accelerate action by sampling an acceleration
    elif act == 3 and ego_vel< (Params.max_speed - epsilon):
        acc = min(2 + np.random.exponential(scale=0.75),Params.actions[act][1])

    #Implements hard decelerate action by sampling an acceleration
    elif act == 4 and ego_vel > (Params.min_speed + epsilon):
        acc = max(-2 - np.random.exponential(scale=0.75),Params.actions[act][1])

    #Implements maintain action by sampling an acceleration value
    elif act == 0 and (ego_vel < (Params.max_speed - epsilon)) and (
        ego_vel > (Params.min_speed + epsilon)):
        acc = np.random.laplace(scale=0.1)
        acc = (acc>=0)*min(acc,0.25)+(acc<0)*max(acc,-0.25)
        
    for idx, new_frame in enumerate(range(frame_id+1, frame_id+SKIP_FRAMES+1)):
        new_vel += acc * timestep
        #Assign the velovity within limits
        if new_vel < Params.min_speed:
            new_vel = Params.min_speed
        elif new_vel > Params.max_speed:
            new_vel = Params.max_speed
    
        # Update current position
        if new_vel == Params.min_speed:
            new_pos += (ego_vel + 0.5*(Params.min_speed-ego_vel))*timestep
        elif new_vel == Params.max_speed:
            new_pos+= (ego_vel + 0.5*(Params.max_speed-ego_vel))*timestep
        else:
            new_pos += (ego_vel+0.5*(acc*timestep))*timestep
            
        temp_lane = ego_lane
        if idx == SKIP_FRAMES-1:            
            temp_lane = new_lane

        ego_df = ego_df._append({"Vehicle_ID": EGO_ID,
                                "Frame_ID": new_frame,
                                "Lane_ID": temp_lane,
                                "Local_Y": new_pos,
                                "Mean_Speed": new_vel,
                                "Mean_Accel": acc,
                                "Vehicle_Length": ego_len,
                                "Vehicle_Class_ID": ego_class_id, 
                                "Follower_ID": ego_follower_id,  #TODO
                                "Leader_ID": ego_leader_id}, ignore_index=True);
        ego_vel = new_vel
        
    # Check if the ego has passed the end of the road
    reached_end = new_pos > Params.end_for_car0        
        
    return reached_end, ego_df

def load_episode_df(directory,ego_id):
    global EGO_ID
    global EPISODE_DF
    
    ego_file = os.listdir(directory+str(ego_id))[0]

    EGO_ID = ego_id
    EPISODE_DF = pd.read_csv(directory+str(ego_id)+"/"+ego_file)
    #'C:\\Users\\syslab123\\Desktop\\Act to Reason - Originaldata/NGSIM_I80_quadruplets/no_followers/vs_always6/2171/ep_follower_2178.csv'
    EPISODE_DF.Local_Y *= 0.3048
    EPISODE_DF.Mean_Speed *= 0.3048
    EPISODE_DF.Mean_Accel *= 0.3048
    EPISODE_DF.Lane_ID = 7-EPISODE_DF.Lane_ID
    EPISODE_DF.Vehicle_Length *= 0.3048
    
def get_real_final_step():
    real_final_step = EPISODE_DF.loc[(EPISODE_DF['Local_Y']<=Params.end_for_car0)&(
        EPISODE_DF['Vehicle_ID']==EGO_ID)].iloc[-1].Frame_ID.item()
        
    
    return real_final_step

#def load_section_df(start_frame):
#    global SECTION_DF
#    
#    SECTION_DF = EPISODE_DF.loc[(EPISODE_DF['Frame_ID']>=start_frame)&(EPISODE_DF['Frame_ID']<(start_frame+SECTION_DUR*SAMPLING_FREQ))]
    
def run_episode(final_state_df,  state_no, run_no, save_dir="", ): 
    ego_dyn_state = np.zeros((1,1,DYNAMIC_STATE_SIZE))
    hist_action_size = int(Params.dynamic_history_action)
    counter = 0
    total_timesteps = 0 
    state_size = 10
    state_no = state_no
    actionget = 0
    ego_df_columns = EGO_DF_DYN_COLS                    
    new_episode_df = EPISODE_DF.copy()
    
    ego_df = EPISODE_DF.loc[EPISODE_DF['Vehicle_ID']==EGO_ID].iloc[[0]].copy()
    ego_len = ego_df['Vehicle_Length'].item()
    
    frames = EPISODE_DF[EPISODE_DF.duplicated(subset='Frame_ID',keep='first')==False].Frame_ID;

    prev_frame_id = frames.iloc[0]
    for frame_id in frames:
        if not(frame_id == frames.iloc[0]) and 0 < frame_id - prev_frame_id < SKIP_FRAMES:
            continue
        if frame_id == frames.iloc[0]:
            ego_position = ego_df['Local_Y'].item()
            ego_lane = ego_df['Lane_ID'].item()
            currentstate_list = get_Message(frame_id=frame_id, ego_current_df=ego_df, normalize=True) #state of the ego car
        else:
            ego_position = ego_df.iloc[[-1]]['Local_Y'].item()
            ego_lane = ego_df.iloc[[-1]]['Lane_ID'].item()
            currentstate_list = get_Message(frame_id=frame_id, ego_current_df=ego_df.iloc[[-1]], normalize=True) #state of the ego car

        currentstate = np.reshape(currentstate_list, [1, 1, STATE_SIZE])

        if (Params.start_merging_point + ego_len) < ego_position < Params.end_merging_point and ego_lane == 0:
            remove_merging = False
        else:
            remove_merging = True
        
        if Params.dynamic_history_action:
            scale_action = 1.0 if not Params.scale_action else (Params.num_actions-1.0)
            ego_dyn_state[0,0,STATE_SIZE:] = np.concatenate((
                                    ego_dyn_state[0, 0, :STATE_SIZE:].copy(),[actionget/scale_action],
                                    ego_dyn_state[0,0,STATE_SIZE:-state_size].copy()))
        else:
            ego_dyn_state[0,0,STATE_SIZE:] = ego_dyn_state[0,0,:-STATE_SIZE:].copy()
        ego_dyn_state[0,0,0:STATE_SIZE] = currentstate[0,0,:].copy() # fill in current actions
        if counter == 0:
            for s_i in range(Params.dynamic_history,1,-1):
                idx_1 = ((s_i-1)*state_size-hist_action_size)
                idx_2 = s_i*state_size-2*hist_action_size
                ego_dyn_state[0,0,idx_1:idx_2] = currentstate[0,0,:].copy()
        currentstate = ego_dyn_state.copy()
               
        if (Params.start_merging_point + ego_len) < ego_position < Params.end_merging_point and ego_lane == 0:
            remove_merging = False
        else:
            remove_merging = True
        reward = 0 
        ego_info = DYNAMIC_AGENT.act(state=currentstate, remove_merging=remove_merging, get_qvals=False) #action taken by the ego car
        dynamic_q_values = ego_info[0][1]

        dynamic_action_type = ego_info[0][0]
        dynamic_actionget = ego_info[0][1]
        action_type = ego_info[1][0]
        actionget = ego_info[1][1]

        # Level-1 Model Output
        #q_values1 = ego_info[1][0][1]
        # Level-2 Model Output
        #q_values2 = ego_info[1][1][1]
        # Level-3 Model Output
        #q_values3 = ego_info[1][2][1]
        # Driving Action


        #Take action and update state
        ego_reached_end, ego_df = update_motion(ego_df = ego_df, frame_id = frame_id, act = actionget) #6 ROWS
        nextstate = get_Message(frame_id,ego_df.iloc[-1],normalize=True)
        [done,ego_state] = collision_check(frame_id = frame_id, ego_df = ego_df) #Checks whether a crash occured
        
        x_data = EPISODE_DF.loc[(EPISODE_DF['Frame_ID'] == frame_id) & (EPISODE_DF['Vehicle_ID'] == EGO_ID), 'Local_Y'].item()
        x_sim = ego_df['Local_Y'].iloc[-1]  # Simulated x-position

        lane_data = EPISODE_DF.loc[(EPISODE_DF['Frame_ID'] == frame_id) & (EPISODE_DF['Vehicle_ID'] == EGO_ID), 'Lane_ID'].item()
        lane_sim = nextstate[7]

        reward = 3 #State.get_reward( ego_reached_end,  ego_state) #TODO
        reward = get_reward(crash=done, nextstate=nextstate, 
                            ego_velocity=nextstate[6], ego_lane=nextstate[7], 
                            fc_d=nextstate[2], dist_end_merging=nextstate[8]    , 
                            x_sim=x_sim, x_data=x_data, lane_sim=lane_sim, lane_data=lane_data)

        total_timesteps += 1
        
        if not done and ego_reached_end:
            ego_state = 4
        
        for new_frame_id in range(frame_id+1,frame_id+SKIP_FRAMES+1):
            df_index = new_episode_df.index[(new_episode_df['Frame_ID']==new_frame_id) & (new_episode_df['Vehicle_ID']==EGO_ID)]
            ego_row = ego_df.loc[ego_df['Frame_ID']==new_frame_id]
            new_episode_df.at[df_index[0],'Lane_ID']=ego_row.Lane_ID.item()
            new_episode_df.at[df_index[0],'Local_Y']=ego_row.Local_Y.item()
            new_episode_df.at[df_index[0],'Mean_Speed']=ego_row.Mean_Speed.item()
            new_episode_df.at[df_index[0],'Mean_Accel']=ego_row.Mean_Accel.item()

        # Breaks the episode if ego cars crashes
        if ego_state != 1:
            nextstate = np.reshape(nextstate, [1, 1,  Params.num_observations])  
            remember_frame(currentstate = currentstate, 
                                            actionget = actionget,
                                            nextstate = nextstate,
                                            reward = reward,
                                            done = done,
                                            ego_reached_end = ego_reached_end,
                                            state_size = Params.num_observations,
                                            dynamic_actionget = dynamic_actionget)
            current_training_loss = 0
            if total_timesteps > Training.replay_start_size and total_timesteps % 4 == 0:
                    current_training_loss = DYNAMIC_AGENT.replay(Training.batch_size, state_no)[0] #Experience replay #not suree

                
           
        
            # Update Target Network every target_up steps
            if total_timesteps % Training.target_up == 0:
                DYNAMIC_AGENT.update_target_model()          
                                
                    
        if done:               
            if ego_state == 1:
                
                total_timesteps -= 1
                counter -= 1
                print("==============================================")
                print("================IGNORE CRASH==================")
            print("==============================================")    
            print('Collusion at step ' + str(frame_id+SKIP_FRAMES) + ': '+ translate_car0_state(ego_state))
            print("The original step: " + str(frames.iloc[-1]))
            print("==============================================" +'\n', end = '\n')
            break
        
        if ego_reached_end:
            break
        
        prev_frame_id = frame_id


    if  not done:
        print("****************************************")
        print("Ego completed episode on time at step " + str(frame_id+SKIP_FRAMES))
        print("The original final step: " + str(frames.iloc[-1]))
        if ego_reached_end:
            print("Ego reached the end")
        else:
            print("Ego DID NOT reach the end")
        print("****************************************"+'\n', end = '\n')   

    DynamicDQNAgent.update_temperature(step = (1.0/boltzmann_decay_end_state))
    # self.training_agent.T = np.maximum(self.training_agent.T * 
    #                                    (1.0/boltzmann_decay_end_state), 
    #                                    1) 

    path_and_directory = 'C:\\Users\\syslab123\\Desktop\\Act to Reason - Original\\Act-to-reason-original\\training_data_results'
    #directory = self.file_config["directory"]
    #Save the weights at the end of each 100 episodes
    fname = './'+path_and_directory+'/models/model'+str(state_no)
    tfname = './'+path_and_directory+'/target_weights/target_weight'+str(state_no)+'.h5'

    DynamicDQNAgent.save(fname,tfname, backup=True)
    DynamicDQNAgent.save_memory(path_and_directory+
                                    "/agent_data/agent_memory"+str(state_no)+".pickle")
    DynamicDQNAgent.save_config(total_timesteps, path_and_directory+
                                    "/agent_data/agent_config"+str(state_no)+".pickle")

    #state_no += 1

        
    real_final_step = EPISODE_DF.loc[(EPISODE_DF['Local_Y']<=Params.end_for_car0)&(EPISODE_DF['Vehicle_ID']==EGO_ID)]
    final_state_df = final_state_df._append({'Run_No':run_no,
                                            'Final_State':ego_state,
                                            'Real_Final_Step': real_final_step.iloc[-1].Frame_ID.item(),
                                            'Sim_Final_Step':(frame_id+SKIP_FRAMES)},ignore_index=True)
    new_episode_df = new_episode_df.loc[new_episode_df['Frame_ID']<=(frame_id+SKIP_FRAMES)]
    new_episode_df.to_csv(EXP_RES_DIR+"/"+save_dir+str(run_no)+".csv", 
                          index = None, 
                          header=True)

    counter += 1
    return final_state_df

def run_section(final_state_df, run_no, save_dir=""): 
    ego_dyn_state = np.zeros((1,1,DYNAMIC_STATE_SIZE))
    hist_action_size = int(Params.dynamic_history_action)
    state_size = STATE_SIZE + hist_action_size
    actionget = 0
                    
    new_section_df = SECTION_DF.copy()
    
    ego_df = SECTION_DF.loc[SECTION_DF['Vehicle_ID']==EGO_ID].iloc[[0]].copy()
    ego_len = ego_df['Vehicle_Length'].item()
     
    frames = SECTION_DF[SECTION_DF.duplicated(subset='Frame_ID',keep='first')==False].Frame_ID.values
    start_frame = frames[0]
    prev_frame_id = frames[0]
    counter = 0
    for frame_id in frames[0:(SECTION_DUR*SAMPLING_FREQ-SKIP_FRAMES+1)]:
        if not(frame_id == frames[0]) and 0 < frame_id - prev_frame_id < SKIP_FRAMES:
            continue
        
        if frame_id == frames[0]:
            ego_position = ego_df['Local_Y'].item()
            ego_lane = ego_df['Lane_ID'].item()
            currentstate_list = get_Message(frame_id=frame_id, 
                                            ego_current_df=ego_df, 
                                            normalize=True) #state of the ego car
        else:
            ego_position = ego_df.iloc[[-1]]['Local_Y'].item()
            ego_lane = ego_df.iloc[[-1]]['Lane_ID'].item()
            currentstate_list = get_Message(frame_id=frame_id, 
                                            ego_current_df=ego_df.iloc[[-1]], 
                                            normalize=True) #state of the ego car
    
        currentstate = np.reshape(currentstate_list, [1, 1, STATE_SIZE])
               
        if (Params.start_merging_point + ego_len) < ego_position < Params.end_merging_point and ego_lane == 0:
            remove_merging = False
        else:
            remove_merging = True
        
        if Params.dynamic_history_action:
            scale_action = 1.0 if not Params.scale_action else (Params.num_actions-1.0)
            ego_dyn_state[0,0,STATE_SIZE:] = np.concatenate((
                                    ego_dyn_state[0, 0, :STATE_SIZE:].copy(),[actionget/scale_action],
                                    ego_dyn_state[0,0,STATE_SIZE:-state_size].copy()))
        else:
            ego_dyn_state[0,0,STATE_SIZE:] = ego_dyn_state[0,0,:-STATE_SIZE:].copy()
        ego_dyn_state[0,0,0:STATE_SIZE] = currentstate[0,0,:].copy() # fill in current actions
        if counter == 0:
            for s_i in range(Params.dynamic_history,1,-1):
                idx_1 = ((s_i-1)*state_size-hist_action_size)
                idx_2 = s_i*state_size-2*hist_action_size
                ego_dyn_state[0,0,idx_1:idx_2] = currentstate[0,0,:].copy()
        currentstate = ego_dyn_state.copy()

        ego_info = DYNAMIC_AGENT.act(state=currentstate, 
                                     remove_merging=remove_merging, 
                                     get_qvals=False) #action taken by the ego car
        actionget = ego_info[1][1] #TODO dynamic action istiyor muyuz yoksa driving action mi bu contextte

        #Take action and update state
        ego_reached_end, ego_df = update_motion(ego_df = ego_df, 
                                                frame_id = frame_id, 
                                                act = actionget)
        [done,ego_state] = collision_check(frame_id = frame_id, 
                                           ego_df = ego_df) #Checks whether a crash occured
        
        for new_frame_id in range(frame_id+1,frame_id+SKIP_FRAMES+1):
            df_index = new_section_df.index[(new_section_df['Frame_ID']==new_frame_id) & (
                new_section_df['Vehicle_ID']==EGO_ID)]
            ego_row = ego_df.loc[ego_df['Frame_ID']==new_frame_id]
            if not df_index.empty: #TODO burasinin acil duzeltilmesi gerekiyor olabilir, final step kaydedilmesi acisindan
                # Proceed with updating the DataFrame
                new_section_df.at[df_index[0], 'Lane_ID'] = ego_row.Lane_ID.item()
                new_section_df.at[df_index[0], 'Local_Y'] = ego_row.Local_Y.item()
                new_section_df.at[df_index[0], 'Mean_Speed'] = ego_row.Mean_Speed.item()
                new_section_df.at[df_index[0], 'Mean_Accel'] = ego_row.Mean_Accel.item()
            else:
                # Handle the case where df_index is empty
                print(f"No data found for Frame_ID: {new_frame_id} and Vehicle_ID: {EGO_ID}")

        # Breaks the episode if ego cars crashes
        if done:              
            if ego_state == 1:
                print("==============================================")
                print("================IGNORE CRASH==================")
            print("==============================================")    
            print('Collusion at step ' + str(frame_id+SKIP_FRAMES) + ': '+ translate_car0_state(ego_state))
            print("The original step: " + str(start_frame+(SECTION_DUR*SAMPLING_FREQ)))
            print("==============================================" +'\n', end = '\n')
            break
        
        prev_frame_id = frame_id

    if not done:
        print("****************************************")
        print("Ego completed section at step " + str(frame_id+SKIP_FRAMES))
        print("The original final step: " + str(start_frame+(SECTION_DUR*SAMPLING_FREQ)))
        print("****************************************"+'\n', end = '\n')   
        
    final_state_df = final_state_df._append({'Run_No':run_no,
                                            'Final_State':ego_state,
                                            'Real_Final_Step': start_frame+(SECTION_DUR*SAMPLING_FREQ),
                                            'Sim_Final_Step':(frame_id+SKIP_FRAMES)},ignore_index=True)
    new_section_df = new_section_df.loc[new_section_df['Frame_ID']<=(frame_id+SKIP_FRAMES)]
    new_section_df.to_csv(EXP_RES_DIR+"/"+save_dir+str(run_no)+".csv", 
                          index = None, 
                          header=True);
    counter += 1
    return final_state_df

def select_path(experiment_title, model_dynamic):
    global MODEL_DYNAMIC
    global EXPERIMENT_PATH
    global EXPERIMENT_TITLE
    global EXP_RES_DIR

    MODEL_DYNAMIC = model_dynamic
    EXPERIMENT_TITLE = experiment_title 
    EXPERIMENT_PATH = os.path.split(os.getcwd())[0]+"/experiments/"+EXPERIMENT_TITLE
    if ENABLE_RANDOM_DYNAMIC_STRATEGY:
        EXP_RES_DIR = RESULTS_PATH+EXPERIMENT_TITLE+"dynM"+str(MODEL_DYNAMIC)    
    else:
        EXP_RES_DIR = RESULTS_PATH+EXPERIMENT_TITLE+"dynRandom"
    Path("./"+EXP_RES_DIR).mkdir(parents=True, exist_ok=True)

def load_dynamic_model():
    global DYNAMIC_AGENT

    MODEL_CONFIG = {"models":{1: MODEL_LEVEL1,
                          2: MODEL_LEVEL2,
                          3: MODEL_LEVEL3,
                          4: MODEL_DYNAMIC}}
    
    agent_levelk_paths = {1:None,2:None,3:None}
    for i in range(1,4):
        agent_levelk_paths[i] = EXPERIMENT_PATH+"level"+str(i)+\
                                  "/training/models/model"+\
                                  str(MODEL_CONFIG["models"][i])
                                  
    levelk_config = {"paths": agent_levelk_paths, "boltzmann_sampling": ENABLE_DYNAMIC_DRIVING_BOLTZMANN_SAMPLING}
    DYNAMIC_AGENT = DynamicDQNAgent(DYNAMIC_STATE_SIZE,
                                    DYNAMIC_ACTION_SIZE, 
                                    STATE_SIZE, ACTION_SIZE,
                                    levelk_config) 
    if not ENABLE_RANDOM_DYNAMIC_STRATEGY:
        DYNAMIC_AGENT.load(EXPERIMENT_PATH+"/dynamic/training/models/model"+str(MODEL_DYNAMIC))
    DYNAMIC_AGENT.T = DYNAMIC_AGENT.MIN_T
    DYNAMIC_AGENT.boltzmann_sampling = ENABLE_BOLTZMANN_SAMPLING
    DYNAMIC_AGENT.random_dynamic_strategy = ENABLE_RANDOM_DYNAMIC_STRATEGY

def main():
    train_episode = True
   # simulate_section = True
    
    experiment_titles = ["some_title/"]

    model_dynamic_list = [99]

    #num_runs = 20
    num_runs = 1 

    directory = DATA_PATH+"NGSIM_I80_quadruplets/"
    
    # If some egos are  not needed to be simulated, skip them
    #skip_egos = [146,164,1066,1173,1193,1214,1340,1554,1559,1563,1666,1716,1724,1778,1922,2168]
    skip_egos = []
    # skip_egos = [146,164,375,376,491,798,1066,1173,1193,1214,1340,1554,1559,1563,1666,1716,1724,1778,1922,2168,2187,2344,2354,2782,2799,3006,3051,3097]
    
    # Select and load dynamic model
    for idx_path, experiment_title in enumerate(experiment_titles):
        print("\n"+experiment_title)
        model_dynamic = model_dynamic_list[idx_path] #model dynamic 99
        select_path(experiment_title, model_dynamic)
        load_dynamic_model()
        state_no = 0

        # Select follower status
        for idx_follow, follower_status in enumerate(["no_followers/","with_followers/"]):
            print("\n"+follower_status)
            Path("./"+EXP_RES_DIR+"/"+follower_status).mkdir(parents=True, exist_ok=True)
            
            

            # Select ego initial status
            for idx_ego, ego_init_status in enumerate(["vs_always6/","vs_startsat7/"]): #makes sense 
                print("\n"+ego_init_status)
                directories = os.listdir(directory+follower_status+ego_init_status)
                #['1066', '1173', '1193', '1214', '1340', '146', '1554', '1559', '1563', '164', '1666', '1716', '1724', '1778', '1922', '2168', '2171', '2187', '2344', '2354', '2782', '2799', '3006', '3020', '3051', '3097', '375', '376', '491', '798']
                Path("./"+EXP_RES_DIR+"/"+follower_status+ego_init_status).mkdir(parents=True, exist_ok=True)
                #'./C:\\Users\\syslab123\\Desktop\\Act to Reason - Originaldata/NGSIM_I80_sim_results/some_title/dynRandom/no_followers/vs_always6/'
                
                # Select ego id
                for ego_dir in directories:
                    print("EGO_ID: "+ego_dir)
                    
                    """
                    if (follower_status == "no_followers/" and 
                        ego_init_status == "vs_always6/" and 
                        int(ego_dir) in skip_egos):
                        print("Already simulated, skip this ego.\n")
                        continue
                    """
                    load_episode_df(directory = (directory+follower_status+ego_init_status),
                                          ego_id = int(ego_dir))
                    save_dir =  (follower_status+ego_init_status+ego_dir+"/")
                    
                    """
                    if simulate_section:
                        frames = EPISODE_DF[EPISODE_DF.duplicated(subset='Frame_ID',
                                                                  keep='first')==False].Frame_ID.values
                        real_final_step = get_real_final_step()                        
                        frames = frames[frames<=real_final_step]
                        for idx_start_frame in range(len(frames-(SECTION_DUR*SAMPLING_FREQ)+1)):
                            start_frame = frames[idx_start_frame]
                            if idx_start_frame % 5 != 0:
                                print("start_frame "+str(start_frame)+" is skipped.")
                                continue
                            print("\nstart_frame: "+str(start_frame))
                            load_section_df(start_frame)
                            final_state_df = pd.DataFrame(columns=FINAL_STATE_DF_COLUMNS)                
                            
                            section_dir = save_dir + str(start_frame) + "/"
                            Path("./"+EXP_RES_DIR+"/"+section_dir +"runs/").mkdir(parents=True,
                                                                 exist_ok=True)                        
                        
                            # Iterate run
                            for run_no in range(num_runs):
                                print("Run no: "+str(run_no))
                                final_state_df = run_section(save_dir = section_dir + "runs/", 
                                                        final_state_df = final_state_df,
                                                        run_no = run_no)
                            
                            final_state_df.to_csv(EXP_RES_DIR+"/"+section_dir+"final_state.csv", 
                                                  index = None, 
                                                  header=True)
                            del final_state_df
                    """        
                    if train_episode:
                        final_state_df = pd.DataFrame(columns=FINAL_STATE_DF_COLUMNS)                
                        Path("./"+EXP_RES_DIR+"/"+save_dir+"runs/").mkdir(parents=True,
                                                                  exist_ok=True)
                        # Iterate run
                        for run_no in range(num_runs):
                            print("Run / episode no: "+str(run_no))
                            final_state_df = run_episode(save_dir = save_dir+"runs/", 
                                                    final_state_df = final_state_df,
                                                    run_no = run_no, state_no = state_no)
                            state_no += 1
                        
                        final_state_df.to_csv(EXP_RES_DIR+"/"+save_dir+"final_state.csv", 
                                              index = None, 
                                              header=True)
                        del final_state_df

if __name__ == '__main__':
    main()
